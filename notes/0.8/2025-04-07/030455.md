---
robots: By accessing this content, you agree to https://qnfo.org/LICENSE. Non-commercial use only. Attribution required.
DC.rights: https://qnfo.org/LICENSE. Users are bound by terms upon access.
author: Rowan Brad Quni
email: rowan.quni@qnfo.org
website: http://qnfo.org
LinkedIn: https://www.linkedin.com/in/rowan-quni-868006341
ORCID: https://orcid.org/0009-0002-4317-5604
tags: QNFO, AI, ArtificialIntelligence, artificial intelligence, quantum, physics, science, Einstein, QuantumMechanics, quantum mechanics, QuantumComputing, quantum computing, information, InformationTheory, information theory, InformationalUniverse, informational universe, informational universe hypothesis, IUH
created: 2024-11-13T19:54:01Z
modified: 2025-04-07T05:11:37Z
title: "030455"
aliases: [Cult of Popularity]
---

# Cult of Popularity

**How to Make Your TOE Sticky**

The journey into fundamental physics often begins with awe. Stumbling across an equation like the one proposed by Garrett Lisi in 2007 (pictured in image.png), aiming for an “Exceptionally Simple Theory of Everything,” one might feel a sense of wonder. There it is, laid out with elegant mathematical symbols combining terms for gravity, matter, and the elusive Higgs field, attempting to capture all of reality in one concise line. It’s ambitious, almost audacious.

Looking closer, certain symbols might jump out–the prominent appearance of π (pi) and φ (phi) within the coefficients and terms. For some, this might trigger a deeper resonance, tapping into pre-existing questions about the very language we use to describe the universe. One might think, “It’s fascinating to see π and φ used so explicitly here. It connects right to this idea I’ve been pondering...”

“What idea is that?” one might ask oneself, or perhaps an AI assistant.

“Well, I wonder about our standard base-10 system. It feels arbitrary. What if we used ‘natural’ bases instead–numbers linked to the universe itself, like base-π or base-φ (the golden ratio)? Could that change how we see fundamental limits? Things like the Planck constant seem to impose a hard boundary, a discretization limit on resolving information. Could those limits be partly artifacts of our counting system? Maybe using a base tied to geometry or scaling offers a different view?”

It’s a creative impulse–the notion of using the universe’s constants as the very basis of our mathematical descriptions, potentially reframing perceived physical barriers like the Planck scale. While contextually, in Lisi’s specific equation, the φ symbol almost certainly represents a variable scalar field, not the fixed golden ratio constant, seeing both π and φ together can certainly spark such connections. Standard physics views the Planck scale as where our current theories (general relativity and quantum field theory) break down, possibly revealing a discrete spacetime fabric, a physical limit. But the deeper question lingers: does our representation influence our perception of that boundary?

Reflecting on this leads inevitably to another observation. Lisi’s theory, despite its elegance and these intriguing constants, largely faded from mainstream discussion. Why? Why do some ambitious proposals flourish while countless others flounder? How does this perspective influence viewing the differing fates of theories–like Lisi’s seemingly stalled attempt–compared to the enduring persistence of, say, String Theory, which has dominated theoretical physics for decades despite its own significant challenges with experimental testability?

“Exactly!” the internal monologue might conclude. “It makes you wonder why. There are so many proposed Theories of Everything. Yet String Theory, often criticized as untestable ‘just math,’ thrives. It almost feels like there’s a ‘popularity contest’ involved, detached from immediate empirical validation...”

This very line of questioning sets our stage. Is the progression of fundamental physics partly shaped by a “Cult of Popularity”? What truly makes a Theory of Everything (TOE) “sticky”–able to capture attention, generate research, and persist over time–especially when definitive experimental proof remains elusive? And crucially, what lessons can be learned from these dynamics by those daring to propose new foundational ideas today?

In a perfect world, scientific theories like Lisi’s (and many others) would be judged solely on their objective merit. Yet, nearly two decades later, this theory, despite its initial buzz, seems to have largely faded from the mainstream discourse. It joins a vast graveyard of proposed Theories of Everything (TOEs), unification schemes, and quantum gravity models that, despite their ingenuity, failed to gain lasting traction.

Contrast this with String Theory. Decades after its inception, despite persistent criticisms regarding its lack of unique, testable predictions and its complex “landscape” of possibilities, it remains a dominant force in theoretical physics, commanding significant research attention, funding, and institutional support. This disparity forces a fascinating, perhaps uncomfortable, question: To what extent is the progression of fundamental physics influenced by a “Cult of Popularity”? And if such dynamics exist, what lessons can aspiring theorists learn to make their own foundational ideas “sticky”?

In a perfect world, scientific theories would be judged solely on their objective merit: their logical consistency, explanatory power, and, crucially, their agreement with experimental evidence. However, in the rarified air of quantum gravity and TOE research, direct experimental verification lies far beyond our current reach, separated by an immense energy gap to the Planck scale. In this near-vacuum of decisive data, other factors inevitably rush in to influence which theories thrive and which wither. Historical momentum, the elegance and tractability of mathematical tools, perceived unification potential, the influence of key proponents, institutional inertia, and even research “fashions” all play a role. This complex interplay, while driven by genuine intellectual pursuit, can sometimes resemble a popularity contest, where factors other than immediate empirical connection dictate a theory’s visibility and persistence.

To understand these dynamics, let’s analyze various approaches through the lens of “stickiness”—the factors contributing to their acceptance, community engagement, and persistence:

**Analysis of TOE Stickiness Factors (as of early 2025)**

| Group / Theory Name | Research Community Size / Activity | Development Maturity / Literature Volume | Key Strengths (Driving Current Acceptance/Interest) | Key Hurdles (Limiting Broader Acceptance/Progress) | Overall Current Status (Community View) |
|---|---|---|---|---|---|
| String Theory & Related |  |  |  |  |  |
| String Theory / M-Theory | Very Large | Extensive | Unification potential (gravity+gauge), mathematical richness, AdS/CFT connections. | Landscape problem, lack of unique testable predictions, reliance on SUSY/extra D. | Mainstream Contender |
| Supergravity (SUGRA) | Medium (mostly within Strings) | Extensive | Necessary ingredient for Strings, better UV behavior than GR alone. | Incomplete UV (mostly), superseded by full String Theory for unification. | Foundational (for Strings) |
| Loop Quantum Gravity & Related |  |  |  |  |  |
| Loop Quantum Gravity (LQG) | Large | Significant | Background independence, spacetime quantization, non-perturbative QG approach. | Difficulty coupling matter robustly, classical limit questions, fewer calculations. | Mainstream Contender |
| Group Field Theory (GFT) | Medium (within LQG/Tensor) | Developing | Potential path integral/QFT framework for LQG, links to tensor models. | Defining continuum limit, demonstrating emergence of GR dynamically. | Developing Program (LQG related) |
| Discrete / Combinatorial Approaches |  |  |  |  |  |
| Causal Set Theory | Small | Developing | Fundamentally discrete & Lorentz invariant postulate. | Recovering manifold locality, defining dynamics/quantum theory. | Active Alternative / Foundational |
| Causal Dynamical Triangulations (CDT) | Medium | Developing | Shows emergence of 4D spacetime in simulations, calculable via Monte Carlo. | Analytical understanding limited, incorporating matter difficult. | Developing Program |
| Emergent Spacetime / Info-Based |  |  |  |  |  |
| “It from Qubit” / Quantum Info / Holography | Large | Significant (esp. AdS/CFT) | Deep insights from entanglement/information, powerful AdS/CFT dictionary. | Connecting AdS/CFT insights robustly to our (dS) universe, defining bulk dynamics. | Active Alternative / Leading Trend |
| Thermodynamics / Entropic Gravity | Medium (Conceptual Influence) | Developing | Profound conceptual links (black holes), gravity potentially not fundamental. | Developing specific, predictive models beyond general principles is hard. | Foundational Idea / Active Research |
| Modified Field Theories / Geometry |  |  |  |  |  |
| Asymptotic Safety | Medium | Developing | Potential non-perturbative QFT solution for gravity within known framework. | Rigorous proof of fixed point needed, generating unique predictions difficult. | Active Alternative |
| Noncommutative Geometry (NCG) | Medium (Math Phys/Theory overlap) | Significant | Elegant mathematical framework, potential to derive SM structure naturally. | Reliance on specific algebraic choices, testability challenges. | Active Alternative / Math Driven |
| Exceptional Structures / Unification |  |  |  |  |  |
| Garrett Lisi’s E8 Theory | Niche / Individual | Nascent | Bold, simple unification postulate using exceptional structure. | Widely seen as having major flaws (fermions/chirality), little follow-up. | Speculative / Largely Dismissed |
| Octonions / Exceptional Structures | Niche | Nascent | Intriguing mathematical properties with potential links to SUSY/dimensions. | Difficulty building concrete, predictive physical models. | Highly Speculative / Math Driven |

(Note: This table is selective, representing different categories discussed previously).

Why did Lisi’s E8 theory, despite its initial appeal and elegance, fall into the “Speculative / Largely Dismissed” category, while String Theory remains a “Mainstream Contender”? String Theory benefited immensely from its early perceived successes, its deep mathematical connections that opened up new areas of pure math, its ability (via AdS/CFT) to provide tools for other areas of physics, and decades of established infrastructure. Its “stickiness” comes from this rich tapestry of mathematical depth, theoretical connections, and community momentum, even while its empirical connection remains tenuous. Lisi’s theory, conversely, faced specific, strong criticisms early on regarding its handling of known particle physics (fermion generations and chirality) and lacked the established community and calculational framework to readily overcome them or explore alternative formulations.

So, how can someone developing a new foundational theory navigate this complex landscape? First, perhaps it’s worth pausing to ask if aiming for the Theory of Everything is always the most productive goal. There’s an undeniable allure, a grand ambition–perhaps even a certain ego factor–involved in seeking the ultimate equation that governs all of reality. Is it possible that more tangible progress sometimes comes from tackling specific, deep inconsistencies within our current understanding (like quantum measurement or the nature of dark energy) rather than immediate, total unification?

However, assuming one is driven to pursue such a foundational picture–oh, I don’t know, let’s say a hypothesis about an informational universe based on principles like holography, “It from Bit,” and information dynamics, perhaps called ‘Infomatics’–how can they learn from the history of theory acceptance, not just to make their ideas “sticky,” but to steer them towards potential scientific truth, prioritizing active falsification over abstract mathematical beauty? The history of physics reminds us that mathematical elegance, while appealing, can sometimes lead us down paths detached from empirical reality (Dirac’s elegant magnetic monopole remains undiscovered; String Theory’s mathematical depth hasn’t yet translated into testable predictions).

With that caution in mind, here are lessons refocused on navigating the research landscape while aiming for empirical grounding:

 - Solve Observable Problems: Don’t just build a self-consistent mathematical world. Demonstrate clearly how your theory explains actual observed phenomena better than existing models or resolves inconsistencies between experimentally tested theories (like GR and QM). What tangible puzzle does it solve?
 - Build Testable Consistency: Mathematical rigor remains essential, but the focus should be on deriving consequences that touch reality. Where does the mathematical structure lead to predictions, even if only “in principle” for now, that differ from the Standard Model or General Relativity? Explore the theory’s potential empirical interfaces.
 - Prioritize Falsifiable Predictions: This is the bedrock of empirical science. What unique, concrete predictions does the theory make–however futuristic the required experiment might be–that, if contradicted by observation, would force us to abandon or significantly revise the theory? A theory that explains everything potentially explains nothing if it cannot be proven wrong. Seek the Achilles’ heel.
 - Connect, Contrast, and Calculate for Verification: Show the links to known, verified physics, but crucially, highlight where the new theory diverges. Develop the calculational tools needed to explore precisely these points of divergence–the places where experiments could potentially distinguish it.
 - Communicate for Scrutiny: Present the ideas, motivations, and especially the potential points of empirical contact clearly and openly, not just to gain adherents, but to invite rigorous criticism, independent verification, and identification of potential flaws or test strategies. Welcome attempts to break the theory.
 - Embrace Provisionality & Focus: Recognize that any TOE proposal today is almost certainly provisional and likely incomplete. Focus development and communication on the most solid, potentially verifiable or falsifiable aspects, rather than getting lost in grand, untestable philosophical claims. What’s the core, testable nugget?

Applying this lens to our informational universe, the goal wouldn’t just be to create an elegant system based on information principles that could encompass known physics. It would be to relentlessly pursue the unique, testable consequences: Does Infomatics predict specific limits on information processing in black holes? Does it suggest subtle statistical patterns in the CMB arising from underlying computational rules? Does it offer a different mechanism for quantum decoherence with potentially observable signatures? The aim shifts from crafting a potentially popular narrative to building a framework that, however ambitious, ultimately submits itself to the possibility of empirical judgment–the only path towards becoming accepted scientific knowledge rather than just compelling mathematics or philosophy.

The “Cult of Popularity,” while a provocative term, highlights a real aspect of scientific progress in data-starved fields. Understanding these dynamics doesn’t mean abandoning scientific integrity; rather, it means recognizing that a compelling theoretical idea must also be presented, developed, and connected in ways that allow the scientific community to engage with it productively. “Stickiness” isn’t proof of truth, but it grants a theory the invaluable resource of sustained attention and collective brainpower, increasing the chances that its true potential–or its flaws–will eventually be understood. For any new TOE to have a chance, it needs not only to be potentially right but also compellingly communicable and demonstrably fruitful for further investigation.

## Math: The “Solution” to it’s Own Problem

Mathematics is the powerful engine of theoretical physics, providing the language for precise models and predictive calculations. But can this engine sometimes run detached from the tracks of empirical reality? Can the very nature of mathematical exploration inadvertently contribute to the “popularity contest” we sometimes seem to witness, where certain theories gain dominance and persistence for reasons beyond immediate connection to observation?

There’s no denying the profound allure of mathematical elegance. Symmetries, unexpected connections between different mathematical fields, and the sheer internal consistency of a complex framework can feel like signposts pointing towards deeper truth. In fields like quantum gravity or TOE research, where direct experimental signposts are scarce, these aesthetic and logical criteria–the beauty of the equations–often become primary guides. This is natural, yet it carries a risk: a theory might gain adherents and “stickiness” largely because its mathematical structure is compelling and beautiful, even if its foundational assumptions about physical reality are shaky or its unique predictions remain stubbornly untestable.

Furthermore, mathematical tractability creates its own powerful momentum. Once a theory develops a sophisticated mathematical apparatus that allows researchers to perform calculations, solve problems within that framework, and generate results, it fosters activity. As you pointed out, it becomes possible to say, “Well, I did all the equations and all the equations work.” This generates publications, supports careers, and builds a community skilled in those specific techniques. It creates an inertia that favors working within the established mathematical machinery over questioning its fundamental applicability or pursuing less mathematically developed alternatives. This research activity, driven by the solvability of problems defined by the theory’s math, significantly contributes to its “popularity” and persistence, sometimes irrespective of progress on the empirical front.

This focus on manipulating the established machinery can sometimes overshadow deeper foundational questions about the mathematical tools themselves. Critiques concerning the potential limitations of base-10, the interpretation of singularities arising from concepts like zero, or the necessity versus convenience of complex numbers might be sidelined. Why? Because the existing mathematical framework, despite these potential philosophical or foundational issues, works for generating calculations and results within its own domain. Developing an entirely new mathematical language–say, one based fundamentally on natural patterns and ratios like π, an “Informatics”–that is equally powerful and predictive is an immense task. The sheer utility and established nature of the current mathematical toolkit create a high barrier for fundamentally different approaches, making the existing formalism the path of least resistance, further cementing its dominant position.

History offers cautionary notes. Dirac’s prediction of the magnetic monopole was mathematically elegant and flowed naturally from his equations, yet monopoles remain elusive. String Theory presents a modern, complex example where extraordinary mathematical depth and elegance have fueled decades of research and profound mathematical discoveries, yet unique, falsifiable predictions about our specific universe remain a major challenge. These aren’t necessarily arguments that the math is wrong, but reminders that mathematical consistency and beauty within a theoretical framework do not automatically guarantee correspondence with physical reality or immediate empirical success.

Therefore, if mathematics is to be the solution to its own potential problems within physics, it requires more than internal consistency and elegance. The “popularity contest” can arise when mathematical productivity inadvertently becomes a substitute for the harder, often slower, process of seeking empirical validation and falsifiability. The challenge for theoretical physics isn’t to use less math, but to constantly ensure its connection to physical principles and potential observation. For any proposed Theory of Everything to transcend mere “stickiness” and move towards accepted scientific knowledge, its mathematical framework must ultimately be accountable to nature. It must do more than just allow the equations to “work”; it must demonstrably and testably describe the world.

## Forging a Path for Infomatics

We’ve explored the complex landscape of theoretical physics, the allure and pitfalls of mathematical elegance, and the often-frustrating dynamics of how foundational ideas gain traction. Now, how can these insights guide the development of Infomatics? Born from observing nature’s persistent patterns and ratios (like π), questioning the fundamental assumptions of our standard mathematical toolkit (base-10, zero, complex numbers), and perhaps grounded in the Informational Universe Hypothesis (IUH) and Information Dynamics (ID), Infomatics aims to provide a deeper, potentially more ‘natural’ description of reality. Moving Infomatics from its foundational concepts and critiques into a viable scientific contender requires a deliberate strategy, one informed by the very dynamics we’ve analyzed.

The goal cannot simply be to create another elegant mathematical system that could describe the universe, nor just to critique the perceived flaws in current methods. To gain genuine scientific consideration and achieve a “stickiness” rooted in potential truth rather than mere novelty or sociological factors, Infomatics must actively engage with the process of scientific validation. Here’s how the lessons learned might apply:

 - Target Specific Physical Puzzles: The initial appeal of Infomatics lies in its foundational premise. To translate that appeal into scientific momentum, it must demonstrate explanatory power on concrete problems. Where can an information-centric approach, perhaps utilizing novel mathematical structures based on natural constants, offer unique leverage? Can Infomatics provide a clearer resolution to the black hole information paradox than existing approaches? Can its view on discretization resolve singularities differently than LQG? Could the values of fundamental constants or particle mass ratios emerge naturally from its informational principles? Identifying and tackling such specific, well-defined puzzles is crucial to showcase Infomatics’ potential beyond a philosophical framework.
 - Develop “Infomatics Native” Rigor and Tools: Facing the inevitable “Where’s the math?” challenge requires a constructive answer. If standard formalisms are deemed insufficient or artifact-prone, Infomatics requires the development of its own self-consistent mathematical or computational language. This might involve pioneering work in:
   - Formalisms explicitly using bases like π or φ, exploring their algebraic and analytical properties in physical contexts.
   - Developing models based on network dynamics, cellular automata, or graph rewriting systems where information rules directly dictate evolution.
   - Creating calculational tools–perhaps novel simulation techniques or analytical methods–that allow deriving quantitative consequences within the Infomatics framework. This demonstrates internal coherence and provides a means for testing.
 - Seek Empirical Anchors, Not Just Internal Elegance: While Infomatics possesses its own form of elegance rooted in natural patterns, its concepts must connect to measurable reality. What is the precise physical meaning of “information” in this context? How do the proposed dynamics relate to established physical quantities like energy, momentum, curvature, or entropy? The focus must be on building bridges between the theory’s abstract concepts and potential observables. Elegance should ultimately manifest in how well it explains observed phenomena.
 - Prioritize Falsifiable Divergences: This is perhaps the most critical step in moving beyond critique towards a scientific proposal. Where, specifically, would the predictions of Infomatics differ from General Relativity or the Standard Model?
   - Does its informational view predict subtle deviations from quantum mechanics in certain regimes?
   - Does a base-π or base-φ mathematical structure lead to different predictions for particle scattering or field propagation at extreme energies?
   - Does its approach to discretization imply unique signatures in the cosmic microwave background or gravitational wave signals?
   - Identifying these potential points of empirical conflict–how could Infomatics be proven wrong?–is essential for its scientific credibility, even if the necessary experiments are decades away.
 - Communicate the Unique Physical Contribution: Beyond critiquing existing math or highlighting patterns, what is the core new physical principle Infomatics introduces? Is it that information is the fundamental substance? That dynamics are governed by specific ratios? That the mathematical language must match these ratios? Articulating this unique contribution clearly, showing how it connects to foundational ideas like Holography or It from Bit while offering something distinctly new, is vital for the community to grasp its potential significance.

Forging the path for Infomatics means running the gauntlet that all fundamental theories face. It involves moving from intriguing observations and critiques to a rigorous, predictive framework capable of explaining specific physical phenomena and, crucially, offering unique, falsifiable predictions. It requires not just challenging the existing mathematical language but potentially building a new one and demonstrating its power. By embracing this challenge – consciously aiming for empirical accountability alongside conceptual innovation – Infomatics can potentially offer a genuinely new perspective, moving beyond the “popularity contest” to make a lasting contribution to understanding our informational universe.

## Speaking the Language of Existing Physics

Introducing a fundamentally new framework like Infomatics, potentially built on different mathematical primitives (patterns, ratios, information dynamics) and challenging long-held assumptions, faces an inherent communication barrier. The established scientific community predominantly “speaks” the languages of General Relativity, Quantum Field Theory, and, in many circles, String Theory. How can a novel theory, speaking a potentially different dialect, gain a receptive audience and demonstrate its potential power?

A crucial strategy lies in translation and transcendence. If Infomatics genuinely represents a deeper or more unified description of reality–a candidate Theory of Everything–then it must, in principle, be able to explain why previous, less fundamental theories worked so well within their domains. It needs to show how their structures and successes emerge from Infomatics’ own principles under appropriate limits or conditions. This ability to “speak the language” of existing physics is a powerful way to bridge the conceptual gap and build credibility.

Consider the benchmarks:

 - Recovering General Relativity: Can the core principles of Infomatics, when applied to macroscopic scales and appropriate energy densities, lead to equations that approximate or directly yield Einstein’s field equations? Showing how curved spacetime geometry emerges from underlying information dynamics would be a monumental achievement.
 - Explaining Quantum Field Theory / Standard Model: Could the seemingly bizarre rules of quantum mechanics and the specific particle zoo of the Standard Model be understood as consequences of information processing rules, network structures, or fundamental ratios within Infomatics? Can concepts like quantization, superposition, and entanglement be derived naturally?
 - Addressing String Theory: This presents a particularly interesting challenge and opportunity, given String Theory’s prominence and mathematical depth, as well as the criticisms regarding its testability. Instead of merely positioning itself as an alternative to String Theory, could Infomatics potentially illuminate it? For example:
   - Could the AdS/CFT correspondence (holography), a key result from String Theory, be derived or understood more fundamentally from the informational principles of Infomatics?
   - Could String Theory’s “landscape” of possible universes be interpreted or constrained by informational limits or principles within Infomatics?
   - Could String Theory’s reliance on complex mathematical structures itself be seen as an effective description emerging from simpler, underlying Infomatics rules?
Successfully translating established physics into the language of Infomatics achieves several critical goals:
 - Validation: It provides strong evidence that Infomatics is not merely an disconnected mathematical or philosophical system, but is grounded in and consistent with observed reality as described by our most successful past theories.
 - Communication: It offers concrete anchor points for researchers trained in conventional methods. Seeing familiar concepts arise within Infomatics makes the new framework vastly more accessible and understandable.
 - Demonstrating Power: Showing that Infomatics can potentially contain GR, QFT, or even aspects of String Theory within its structure strongly suggests it offers a deeper, more comprehensive perspective. It transcends, rather than simply replaces.
 - Building Bridges: It counters skepticism by showing respect for, and explaining the success of, previous scientific achievements, rather than appearing to discard them wholesale.
Therefore, while forging its unique path and identifying its own falsifiable predictions is essential (as discussed previously), a key strategy for Infomatics to gain a significant audience and be taken seriously as a contender must involve demonstrating this power of translation. It needs to show that it can potentially rebuild the familiar structures of modern physics on its new informational foundation. This ability to speak the languages of the theories it seeks to supersede is perhaps the most convincing way to persuade the existing scientific community to invest the effort in learning the new language Infomatics offers.
