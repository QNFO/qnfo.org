---
robots: By accessing this content, you agree to https://qnfo.org/LICENSE. Non-commercial use only. Attribution required.
DC.rights: https://qnfo.org/LICENSE. Users are bound by terms upon access.
author: Rowan Brad Quni
email: rowan.quni@qnfo.org
website: http://qnfo.org
LinkedIn: https://www.linkedin.com/in/rowan-quni-868006341
ORCID: https://orcid.org/0009-0002-4317-5604
tags: QNFO, AI, ArtificialIntelligence, artificial intelligence, quantum, physics, science, Einstein, QuantumMechanics, quantum mechanics, QuantumComputing, quantum computing, information, InformationTheory, information theory, InformationalUniverse, informational universe, informational universe hypothesis, IUH
created: 2024-11-13T19:54:01Z
modified: 2025-04-07T06:03:44Z
title: "120457"
aliases: ["**The Substance Test: A New Framework for Identifying Meaningful Writing in the Age of AI-Generated Drivel**"]
---

# **The Substance Test: A New Framework for Identifying Meaningful Writing in the Age of AI-Generated Drivel**

## **Introduction: The Crisis of Empty Discourse**

We live in an era of unprecedented textual production. Between academic journals, corporate reports, AI-generated content, and the endless churn of online media, more words are being written than ever before—yet much of it says nothing at all. This is not merely an AI problem; human-generated writing is often just as hollow, dressed up in jargon, structural conventions, and false authority. The result is a growing mass of **drivel**: text that consumes attention without providing substance.

Traditional methods of evaluation—peer review, editorial oversight, even human intuition—are failing to filter out this emptiness. We need a new way to assess whether writing is worth reading, one that works across genres, disciplines, and sources (human or machine).

This paper presents **The Substance Test**, a three-part framework designed to cut through drivel by evaluating writing on its ability to:

1. **Change how someone thinks or acts** (not just inform).
2. **Bear the unique fingerprints of its creator** (not just rehash consensus).
3. **Take meaningful risks** (not just hedge toward safety).

Unlike checklists or scoring rubrics, this test is **principled rather than procedural**, making it resistant to gaming. Below, we define each criterion, demonstrate its application, and show how it can be used to separate signal from noise in any domain.

---

## **1. The Change Criterion: Does This Writing Alter Behavior or Understanding?**

### **The Problem**

Most writing fails the simplest question: *So what?* A paper may be technically correct, well-structured, and cite all the right sources—yet leave no mark on its reader. This is the essence of drivel: consumption without consequence.

### **The Test**

Substantive writing must contain at least **one claim or insight that would compel a reader to:**

- **Act differently** (e.g., change a research approach, adopt a new method).
- **Think differently** (e.g., abandon a prior assumption, see a problem in a new light).
- **Investigate further** (e.g., seek out primary sources to verify or refute the claim).

If the text only **describes, summarizes, or contextualizes**, it is likely drivel.

### **Examples**

❌ *Drivel:* “Recent advances in machine learning have transformed many industries.”

✅ *Substantive:* “Stop using ROC curves for imbalanced datasets—here’s why precision-recall fails too, and what to use instead.”

### **Application**

To apply this test:

1. Scan the text for claims that **could not be deleted without loss of meaning**.
2. Ask: *If I remember nothing else from this, would this one idea change anything?*
3. If no such claim exists, the text fails.

---

## **2. The Fingerprint Criterion: Could Only This Author Have Written This?**

### **The Problem**

Much of modern writing is **interchangeable**. AI-generated text is the extreme case (trained on averages, it produces consensus-by-design), but human writing often falls into the same trap. Academics mimic disciplinary conventions, corporate writers recycle buzzwords, and journalists repeat press-release narratives. The result is text without a voice.

### **The Test**

Substantive writing must contain **telltale signs of its origin**, such as:

- **Personal experience** (e.g., “We tried X and it failed because...”).
- **Idiosyncratic references** (not just the usual 10 seminal papers).
- **Flawed but revealing logic** (e.g., “I first thought X, but then Y changed my mind”).

If the text could have been written by **anyone familiar with the field**, it is likely drivel.

### **Examples**

❌ *Drivel:* A GPT-generated literature review with perfect balance and zero perspective.

✅ *Substantive:* Feynman’s “Surely You’re Joking,” where his unique voice and stories convey deeper insights than a textbook could.

### **Application**

To apply this test:

1. Look for **anecdotes, unusual citations, or admissions of uncertainty**.
2. Ask: *Does this feel like a human wrote it, or a committee (or algorithm)?*
3. If no unique perspective is detectable, the text fails.

---

## **3. The Risk Criterion: Does This Writing Dare to Be Wrong?**

### **The Problem**

Safe writing is usually drivel. Academics hedge with “may suggest,” corporations speak in platitudes, and AI models default to probabilistically neutral statements. The result is text that **cannot be disagreed with—because it takes no stand**.

### **The Test**

Substantive writing must contain **at least one claim that:**

- Would **anger or annoy** someone invested in the status quo.
- Could **plausibly be challenged** by a knowledgeable reader.
- Is **defensible with evidence** (not just opinion).

If the text only **surveys, summarizes, or balances perspectives**, it is likely drivel.

### **Examples**

❌ *Drivel:* “While some studies show X, others suggest Y.”

✅ *Substantive:* “Peer review rewards drivel because it selects for consensus over insight.”

### **Application**

To apply this test:

1. Highlight sentences that **could not appear in a Wikipedia summary** (too contentious).
2. Ask: *Who would dislike this claim, and why?*
3. If no such claim exists, the text fails.

---

## **Implementation: How to Use The Substance Test**

### **For Readers**

Conduct a **30-Second Audit** on any text:

1. **Change**: Is there one actionable takeaway?
2. **Fingerprint**: Are there signs of a human author?
3. **Risk**: Is there a claim someone might contest?

If all three are present, read deeper. If not, move on.

### **For Writers**

Before publishing, ask:

1. **Change**: What will readers *do* differently after this?
2. **Fingerprint**: Where does my personal perspective appear?
3. **Risk**: What here might draw criticism?

If you can’t answer, revise.

### **For Institutions**

Reform evaluation systems to reward:

- **Provocation over polish** (A+ for risky ideas, C for flawless consensus).
- **Substance over output** (one groundbreaking paper > ten trivial ones).

---

## **Conclusion: A Call for Substance**

The Substance Test is not a scoring rubric but a **philosophical shift**—away from judging writing by its form, and toward evaluating it by its **impact, authenticity, and courage**.

To those who say this standard is too high, we reply: **Good**. The alternative is a world drowning in empty words.

**Final Challenge**: Apply all three criteria to this paper. Does it pass? Where does it fall short? The best writing invites its own autopsy.

---

*Postscript: Earlier drafts of this paper failed the Fingerprint Test by omitting personal stakes. We revised to include this admission—a small but necessary step toward substance.*
