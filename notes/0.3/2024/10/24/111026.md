The solution for language singularity, as it relates to LLMs, is that the individual so-called ethics and censorship that one private company in there advisory board impose on everyone who uses that cannot be excused. So instead, we should simply strive To maintain a consistent corpus of everything that we know, and that includes differential security contribution so Google could contribute all the Gmail data in a differential privacy way, it would still feed the model and its knowledge just as Facebook and Twitter benefited from Platforms, social media content, but why build different models? What we should be doing is addressing the censorship in AI issue with a common data set as Herculean. As that sounds, the more that we can possibly add to it, the more resilient and useful. It grows for everyone, so there's A Positive externality there