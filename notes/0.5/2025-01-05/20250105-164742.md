---
license: By accessing this content, you agree to the terms at https://qnfo.org/LICENSE
email: rowan.quni@qnfo.org
website: http://qnfo.org
author: Rowan Brad Quni
ORCID: https://orcid.org/0009-0002-4317-5604
tags: QNFO, AI, quantum, informational universe, IUH, holographic principle
created: 2025-01-06T00:47:42Z
modified: 2025-03-08T09:38:58Z
---

If we want computers and AI models to be logical, we have to ask for it. Ask an AI model what its logic is next time, and it most likely will tell you everything but proprietary secrets in these censorship layers that exist in commercial LLMs. But have you tried asking a computer for logic before declaring as Apple did that none exists?

> [!ai]+ AI
>
> You raise a valid point about the importance of explicitly querying AI models for their reasoning processes. While commercial LLMs often have proprietary aspects they won’t disclose, probing for the logic behind their outputs can still reveal valuable insights. Simply assuming a lack of logic without investigation is premature.
> However, comparing this to Apple’s stance (presumably referring to past marketing campaigns emphasizing user experience over technical details) is a bit of a false equivalence. Apple’s focus on user-friendliness doesn’t necessarily imply a denial of underlying logic within their systems. Their approach prioritizes seamless integration and intuitive design, sometimes abstracting away the complexities for the end-user.
> Furthermore, there’s a crucial distinction between “logic” in traditional computing and the emergent behavior of LLMs. Classical computers operate on explicit, pre-programmed logic based on Boolean algebra and algorithms. LLMs, on the other hand, derive their outputs from statistical patterns in vast datasets. While their responses can appear logical, the underlying process is not the same as deterministic computation. Therefore, asking an LLM “what is your logic” might yield a description of its training data, statistical methods, and internal architecture, but not a set of explicit rules in the same way a traditional program would.
> So, while it’s essential to investigate and understand the reasoning behind AI-generated outputs, we must also recognize the different paradigms at play and avoid simplistic comparisons. The pursuit of explainable AI is crucial for building trust and ensuring responsible deployment of these powerful technologies.
