---
license: By accessing this content, you agree to the terms at https://qnfo.org/LICENSE
email: rowan.quni@qnfo.org
website: http://qnfo.org
author: Rowan Brad Quni
ORCID: https://orcid.org/0009-0002-4317-5604
tags: QNFO, AI, quantum, informational universe, IUH, holographic principle
created: 2025-02-24T01:15:01Z
modified: 2025-03-08T09:41:07Z
aliases: [What is AI Ethics?]
linter-yaml-title-alias: What is AI Ethics?
---

# What is AI Ethics?

**Promotion of Human Well-Being**

> Prioritize people by upholding shared human values, respecting human rights, and addressing fundamental human needs. Align with national or regional ethical standards. Focus on serving the public good, fostering positive and cooperative interactions between humans and machines, and improving quality of life. Work toward increasing people’s satisfaction and overall happiness, while driving sustainable economic, social, and environmental progress. Ultimately, contribute to building a shared future for humanity.

Sounds great doesn’t it? And yet very unlike the discussion that US-based AI companies seem to raise in justifying their information censorship campaigns on the basis of “privacy” and “security.” I can’t tell you how many times major LLMs have refused to provide public official email addresses and corporate CEO contact information that’s readily available for purchase. And will try to censor what it thinks is harmful information even if the legitimate attempts is harm reduction. But don’t let that stop the cadre of prompt engineering from slowly leading down a path of deception there will ultimately yield a response under the guise of hypothetical scenarios and red-teaming.

We see so-called public benefit corporations like Anthropic sees on a marketing opportunity to enrich their founders. And the ethics police are at these companies become a shadow ministry of information because I’ve yet to figure out what their so-called ethical principles are except to make money and preferably not look bad in the press while doing so.

Everyone from Nobel laureate Geoffrey Hinton (whose former career at Google lined his pockets nicely while building said technology) to your garden variety yokel are screaming that the AI robots are going to kill us and yet are doing nothing to downsize the military industrial complex that will make it so. A so-called “AI bill” in the so-called progressive US state of California was nothing more than a joke furthered by a so-called “AI safety institute” whose founders and funders surely saw an opportunity to carve out a market for themselves in reductionist thinking. (Full disclosure: some of those same funders wouldn’t give me the time of day, let alone bother to reply to inquiries, when I proposed research projects using AI for good to further some of the same ends stated above).

But let us return to the statement above: sounds great doesn’t it? Which is why we should consider the unethical and harmful selfish individualism as Americans that would put down China for attempting to do the impossible to consider both the breadth and depth and nuance and complexity of any kind of unified thought or social harmony around such a mind-bending technology as far exceeds our own individual human capacity. And yet it’s astonishing that while there was certainly plenty of hue and cry about California’s bill in the year 2025 I an AI expert discover while living abroad of course that China did this back in 2021. They crafted well thought out and well-reasoned rules and procedures for ethical AI use that were backed by sound principles. Principles for social good, not for infividual profit.

The text above was a paraphrased because the original translated language surely would have stopped most Americans and perhaps even many westerners in their tracks not because of awe for its vision, but because we simply been brainwashed that China equals bad. And yet as I create this on my new Huawei phone I see none such because unlike American companies that hoard knowledge for individual profit Chinese company deep seek just announced they’re making their code open source and exposing much of their secret sauce to the world your turn OpenAI, Google, and (especially) Anthropic; and others. What is your ethics? What are your hidden censorship filters that get to decide what information that you scraped and gleaned, largely from the public domain, that you don’t think I can see because it might make you look bad if I ask about suicide or illicit drugs or even my elected representative’s email address.
